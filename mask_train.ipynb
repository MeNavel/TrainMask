{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "import os\n",
    "from keras.layers import Conv2D, MaxPooling2D,Activation,Flatten, Dense, Dropout,InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import face_recognition\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import cv2\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./dataset\"\n",
    "name_list = []\n",
    "ftr_list = []\n",
    "size = (224, 224)\n",
    "DIM=224\n",
    "input_shape = (DIM, DIM, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMobileNet():\n",
    "    mobileNet =  MobileNet(include_top=False, weights='imagenet', \n",
    "                                     input_shape=input_shape)\n",
    "\n",
    "    output    = mobileNet.layers[-1].output\n",
    "    output    = keras.layers.Flatten()(output)\n",
    "    ModelmobileNet = Model(inputs=mobileNet.input, outputs=output)# base_model.get_layer('custom').output)\n",
    "\n",
    "    ModelmobileNet.trainable = False\n",
    "    for layer in ModelmobileNet.layers:\n",
    "        layer.trainable = False\n",
    "    return ModelmobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesMobileNet(model, input_imgs):\n",
    "    features = model.predict(input_imgs, verbose=0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data ... \n",
      "luluk\n",
      "devi\n",
      "firsa\n",
      "febri\n",
      "sintia\n",
      "supardi\n",
      "tikah\n",
      "rima\n",
      "hidayatul\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Data ... \")\n",
    "for name in os.listdir(path):\n",
    "    print(name)\n",
    "    for file in os.listdir(path + \"/\" + name + \"/no_mask\"):\n",
    "        if file == \".DS_Store\":\n",
    "            continue\n",
    "        filename = path + \"/\" + name + \"/no_mask/\" + file\n",
    "        \n",
    "        \n",
    "        \n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.resize(img, size)\n",
    "        ftr_list.append(img)\n",
    "        name_list.append(\"no_mask\")\n",
    "        \n",
    "    for file in os.listdir(path + \"/\" + name + \"/mask\"):\n",
    "        if file == \".DS_Store\":\n",
    "            continue\n",
    "        filename = path + \"/\" + name + \"/mask/\" + file\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.resize(img, size)\n",
    "        ftr_list.append(img)\n",
    "        name_list.append(\"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data telah terload ... Done\n"
     ]
    }
   ],
   "source": [
    "name_np = np.array(name_list)\n",
    "ftr_np = np.array(ftr_list)\n",
    "print(\"Data telah terload ... Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check komposisi data\n",
      "[['mask' '389']\n",
      " ['no_mask' '398']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Check komposisi data\")\n",
    "(unique, counts) = np.unique(name_np, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data yg kurang dari 5\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "less5=unique[counts<5]\n",
    "print(\"Data yg kurang dari 5\")\n",
    "print(less5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hapus data yg kurang dari 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Hapus data yg kurang dari 5\")\n",
    "for i in range(0,len(less5)):\n",
    "    idx = np.where(name_np==less5[i])\n",
    "    ftr_np = np.delete(ftr_np,idx,axis=0)\n",
    "    nrp_np = np.delete(name_np,idx)\n",
    "(unique, counts) = np.unique(name_np, return_counts=True)\n",
    "numClass=len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(numClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melabeli nama dengan angka\n",
    "#ex : anisa:0, dafa:1, danang:2\n",
    "mapLabel = dict()\n",
    "for i in np.unique(name_np):\n",
    "    mapLabel[i] = len(mapLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mask': 0, 'no_mask': 1}\n"
     ]
    }
   ],
   "source": [
    "print(mapLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate nilai 0,1,2 untuk tiap data\n",
    "classLabel=[]                        \n",
    "for i in name_np:\n",
    "    classLabel.append(mapLabel[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(classLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_category = to_categorical(classLabel,numClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse numbers as floats\n",
    "ftr_np_float = ftr_np.astype('float32')\n",
    "# Normalize data\n",
    "ftr_np_float = ftr_np / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "fold_no = 1\n",
    "verbosity = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelmobileNet = createMobileNet()\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobileNet Predict for get Features\n",
      "##################################\n",
      "Train Bottleneck Features: (393, 50176) \n",
      "Validation Bottleneck Features: (394, 50176)\n",
      "Created Model 3\n",
      "#########################\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Score for fold 3: 0.9873096446700508\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(ftr_np_float, name_category):\n",
    "    x_train, x_test = ftr_np_float[train_index], ftr_np_float[test_index]\n",
    "    y_train, y_test = name_np[train_index], name_np[test_index]\n",
    "    print(\"mobileNet Predict for get Features\")\n",
    "    print(\"##################################\")    \n",
    "    x_trainMobileNet = getFeaturesMobileNet(ModelmobileNet, x_train)\n",
    "    x_testMobileNet  = getFeaturesMobileNet(ModelmobileNet, x_test)\n",
    "   \n",
    "\n",
    "    print('Train Bottleneck Features:', x_trainMobileNet.shape, \n",
    "              '\\nValidation Bottleneck Features:', x_testMobileNet.shape)\n",
    "    \n",
    "    print(\"Created Model %d\" %fold_no)#-> model_save)\n",
    "    print(\"#########################\")    \n",
    "    nmModel  = 'mobileNetNN.h5_fold_%d.h5'%fold_no#-> model_save  \n",
    "    #model = LinearDiscriminantAnalysis()\n",
    "    model = LogisticRegression(multi_class='auto',solver='lbfgs', max_iter=1000) \n",
    "        \n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    model.fit(x_trainMobileNet,y_train)    \n",
    "    scores = model.score(x_testMobileNet,y_test)\n",
    "    print(f'Score for fold {fold_no}: {scores}')\n",
    "    acc_per_fold.append(scores * 100)\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 -  Accuracy: 98.73096446700508%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 -  Accuracy: 98.73096446700508%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 -  Accuracy: 98.73096446700508%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 98.73096446700508 (+- 0.0)\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} -  Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')    \n",
    "print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
